{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LLM vs compound ai system => RAG\n",
    "2. Compound ai system control logic can be:\n",
    "    - rule-based: coded by humans\n",
    "    - [AGENT] ai-based: dynamically planned by the ai every time (LLM reasoning capability improvement made this possible)\n",
    "3. [AGENT]\n",
    "    - reason (decompose the task)\n",
    "    - act, by calling tools\n",
    "        - external apis\n",
    "        - search the web\n",
    "        - vector database\n",
    "        - calculator\n",
    "        - some other specialist LLMs\n",
    "        - ...\n",
    "    - access memory\n",
    "4. Different Agent types:\n",
    "    - ReAct (reason + act): user query => LLM.pan / think => execute (maybe using external tools) => observe tool return {ko: iterate / ok: answer}\n",
    "5. desinging compound systems\n",
    "    - this is a sliding scale of LLM autonomy from full rule-based to full ai-based\n",
    "    - when the scope is narrow and well defined, it is more efficient to design a rule-based system (e.g. the user is not expected to ask about the weather)\n",
    "    - agentic approach is useful when the deterministic controlflow would get too complicated (so we don't mind the time and cost each individual execution takes compared to the time and cost developping the programatic approach would take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When importing files from a different directory, you need to add the directory to the path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the chat_bot directory\n",
    "chat_bot_path = os.path.join(current_dir, '..', 'chat_bot')\n",
    "\n",
    "# Add the chat_bot directory to the Python path\n",
    "sys.path.append(chat_bot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LLM\n",
    "import SDMX_DataFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent demo:\n",
    "1. get the sdmx descriptor for a dataflow\n",
    "2. tokenize the whole of it to estimate cost (and conclude that parsing is king)\n",
    "3. dict / paresed json based solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://sdmx.oecd.org/public/rest/dataflow/OECD.EDU.IMEP/DSD_EAG_UOE_FIN@DF_UOE_INDIC_FIN_PERSTUD/1.0?references=all'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_perstud = {\"agency\": \"OECD.EDU.IMEP\",\n",
    "\"id\": \"DSD_EAG_UOE_FIN@DF_UOE_INDIC_FIN_PERSTUD\",\n",
    "\"version\": \"1.0\",\n",
    "\"name\": \"Expenditure on educational institutions per full-time equivalent student\",\n",
    "\"description\": \"This dataset contains data on expenditure per full-time equivalent student and per full-time equivalent student as a percentage of GPD per capita. The default table displays data for 2020 in current USD PPP and as a percentage of GDP per capita, from all expenditure sources, and unfiltered by type of expenditure. The selection can be changed to display data: by year, by source of expenditure, by destination of expenditure and by type of expenditure. Please note that some categories are mutually exclusive. </p><p>For more information, please consult <a href=\\\"https://www.oecd-ilibrary.org/sites/e13bef63-en/1/3/4/index.html?itemId=%20/content/publication/e13bef63-en&_csp_=a4f4b3d408c9dd70d167f10de61b8717&itemIGO=oecd&itemContentType=book\\\"><i>Education at a Glance 2023</i></a>. Additional details regarding the methodology used, references to the sources, and specific notes for each country can be found in <a href=\\\"https://www.oecd-ilibrary.org/sites/301fa18e-en/index.html?itemId=/content/component/301fa18e-en\\\"><i>Education at a Glance 2023 Sources, Methodologies and Technical Notes</i></a>.\"\n",
    "}\n",
    "\n",
    "dataflow_details_url = f'https://sdmx.oecd.org/public/rest/dataflow/{fin_perstud[\"agency\"]}/{fin_perstud[\"id\"]}/{fin_perstud[\"version\"]}?references=all'\n",
    "dataflow_details_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = SDMX_DataFlow.Dataflow(dataflow_details_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No codelist found for TIME_PERIOD\n"
     ]
    }
   ],
   "source": [
    "df_info.populate_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://openai.com/api/pricing/\n",
    "MODEL_PRICING_PER_M_TOKENS = {\n",
    "    'gpt-4o': {'prompt_tokens': 5.00, 'completion_tokens': 15.00},\n",
    "    'gpt-4o-2024-08-06': {'prompt_tokens': 2.50, 'completion_tokens': 10.00},\n",
    "    'gpt-4o-mini': {'prompt_tokens': 0.150, 'completion_tokens': 0.600},\n",
    "    'gpt-4o-mini-2024-07-18': {'prompt_tokens': 0.150, 'completion_tokens': 0.600},\n",
    "    'o1-preview': {'prompt_tokens': 15.00, 'completion_tokens': 60.00}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url contains #44 tokens\n",
      "df_details_json contains #223203 tokens\n",
      "df_name contains #11 tokens\n",
      "df_description contains #274 tokens\n",
      "df_dimension_names contains #147 tokens\n",
      "df_code_names contains #1029 tokens\n"
     ]
    }
   ],
   "source": [
    "# print the memory size of instance variables\n",
    "import tiktoken\n",
    "\n",
    "# Load the encoding for the GPT model you're using\n",
    "# For GPT-4 or GPT-3.5, you can use the `cl100k_base` encoding\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "for var in vars(df_info):\n",
    "    content = getattr(df_info, var)\n",
    "    text = str(content)\n",
    "    # Tokenize the string\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"{var} contains #{len(tokens)} tokens\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming each answer is always 100 tokens, independent of input size, we can calculate the cost for 1000 calls as follows:\n",
    "\n",
    "**Model Pricing:**\n",
    "- **gpt-4o**: $5.00 / 1M input tokens, $15.00 / 1M output tokens\n",
    "- **gpt-4o-mini**: $0.150 / 1M input tokens, $0.600 / 1M output tokens\n",
    "- **o1-preview**: $15.00 / 1M input tokens, $60.00 / 1M output tokens\n",
    "\n",
    "```python\n",
    "1000 * len(tokens) * MODEL_PRICING_PER_M_TOKENS[model_name]['prompt_tokens'] / 1000000  # Cost of prompt\n",
    "1000 * 100 * MODEL_PRICING_PER_M_TOKENS[model_name]['completion_tokens'] / 1000000      # Cost of completion\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of prompt: 1.116015\n",
      "Cost of completion: 0.0015\n"
     ]
    }
   ],
   "source": [
    "df_info.df_details_json\n",
    "\n",
    "\n",
    "\n",
    "text = str(df_info.df_details_json)\n",
    "# Tokenize the string\n",
    "tokens = encoding.encode(text)\n",
    "print(f\"Cost of prompt: {len(tokens) * MODEL_PRICING_PER_M_TOKENS['gpt-4o']['prompt_tokens'] / 1000000}\")\n",
    "print(f\"Cost of completion: {100 * MODEL_PRICING_PER_M_TOKENS['gpt-4o']['completion_tokens'] / 1000000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o:\n",
      "Total cost for 1000 calls on the raw SDMX metadata: $1117.515\n",
      "Total cost for 1000 calls on the parsed code names: $6.645\n",
      "==========================\n",
      "Model: gpt-4o-mini:\n",
      "Total cost for 1000 calls on the raw SDMX metadata: $33.54045\n",
      "Total cost for 1000 calls on the parsed code names: $0.21434999999999998\n",
      "==========================\n",
      "Model: o1-preview:\n",
      "Total cost for 1000 calls on the raw SDMX metadata: $3354.045\n",
      "Total cost for 1000 calls on the parsed code names: $21.435000000000002\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "# json to text to tokens:\n",
    "raw_json_text = str(df_info.df_details_json)\n",
    "raw_json_tokens = encoding.encode(text)\n",
    "parsed_metadata_text = str(df_info.df_code_names)\n",
    "parsed_metadata_tokens = encoding.encode(parsed_metadata_text)\n",
    "completion_tokens = 100\n",
    "\n",
    "for model_name in (\"gpt-4o\",\"gpt-4o-mini\", \"o1-preview\"):\n",
    "    print(f\"Model: {model_name}:\")\n",
    "    raw_prompt_cost = 1000 * len(raw_json_tokens) * MODEL_PRICING_PER_M_TOKENS[model_name]['prompt_tokens'] / 1000000\n",
    "    parsed_prompt_cost = 1000 * len(parsed_metadata_tokens) * MODEL_PRICING_PER_M_TOKENS[model_name]['prompt_tokens'] / 1000000\n",
    "    completion_cost = 1000 * completion_tokens * MODEL_PRICING_PER_M_TOKENS[model_name]['completion_tokens'] / 1000000\n",
    "    print(f\"Total cost for 1000 calls on the raw SDMX metadata: ${raw_prompt_cost + completion_cost}\")\n",
    "    print(f\"Total cost for 1000 calls on the parsed code names: ${parsed_prompt_cost + completion_cost}\")\n",
    "    print(\"==========================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Challenge of Too Much Data: Finding What’s Relevant for the LLM\n",
    "\n",
    "When working with large datasets like SDMX, there is often **a lot more data than we actually need** to answer specific questions. For example:\n",
    "\n",
    "- A URL might only take up 44 tokens.\n",
    "- The name of a dataframe takes up just 11 tokens.\n",
    "- But the full details of the data (in JSON format) can use **223,153 tokens**!\n",
    "\n",
    "#### The Problem:\n",
    "If the user only asks for something simple, like the name of the dataframe, we don’t need to send all 223,153 tokens. We could give the answer with just 11 tokens. However, if we send all the data to the LLM, it creates two big challenges:\n",
    "1. **Efficiency**: It’s like trying to find a needle in a haystack. The LLM would have to search through tons of unnecessary data to find what matters.\n",
    "2. **Cost**: Sending large amounts of data to the LLM is expensive. The more tokens we use, the higher the cost.\n",
    "\n",
    "#### The Solution:\n",
    "A good idea is to **prepare the data before sending it to the LLM**, which is part of what’s called an \"agentic approach.\" This means we make sure the LLM only gets the important and relevant information it needs to answer the question, rather than flooding it with everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"df_name\": \"Expenditure on educational institutions per full-time equivalent student\",\n",
      "    \"df_description\": \"This dataset contains data on expenditure per full-time equivalent student and per full-time equivalent student as a percentage of GPD per capita. The default table displays data for 2020 in current USD PPP and as a percentage of GDP per capita, from all expenditure sources, and unfiltered by type of expenditure. The selection can be changed to display data: by year, by source of expenditure, by destination of expenditure and by type of expenditure. Please note that some categories are mutually exclusive. </p><p>For more information, please consult <a href=\\\"https://www.oecd-ilibrary.org/sites/e13bef63-en/1/3/4/index.html?itemId=%20/content/publication/e13bef63-en&_csp_=a4f4b3d408c9dd70d167f10de61b8717&itemIGO=oecd&itemContentType=book\\\"><i>Education at a Glance 2023</i></a>. Additional details regarding the methodology used, references to the sources, and specific notes for each country can be found in <a href=\\\"https://www.oecd-ilibrary.org/sites/301fa18e-en/index.html?itemId=/content/component/301fa18e-en\\\"><i>Education at a Glance 2023 Sources, Methodologies and Technical Notes</i></a>.\",\n",
      "    \"df_dimension_names\": {\n",
      "        \"MEASURE\": \"Measure\",\n",
      "        \"REF_AREA\": \"Reference area\",\n",
      "        \"EDUCATION_LEV\": \"Education level\",\n",
      "        \"INTENSITY\": \"Intensity\",\n",
      "        \"EXP_SOURCE\": \"Financing source\",\n",
      "        \"EXP_DESTINATION\": \"Destination of expenditure\",\n",
      "        \"EXPENDITURE_TYPE\": \"Type of expenditure\",\n",
      "        \"INST_TYPE_EDU\": \"Type of educational institution\",\n",
      "        \"PRICE_BASE\": \"Price base\",\n",
      "        \"BASE_PER\": \"Base period\",\n",
      "        \"TIME_PERIOD\": \"Time period\",\n",
      "        \"OBS_VALUE\": \"Observation value\",\n",
      "        \"OBS_STATUS\": \"Observation status\",\n",
      "        \"UNIT_MULT\": \"Unit multiplier\",\n",
      "        \"UNIT_MEASURE\": \"Unit of measure\",\n",
      "        \"DECIMALS\": \"Decimals\"\n",
      "    },\n",
      "    \"df_code_names\": {\n",
      "        \"MEASURE\": {\n",
      "            \"FIN_PERSTUD\": \"Expenditure per full-time equivalent student\"\n",
      "        },\n",
      "        \"REF_AREA\": {\n",
      "            \"ARG\": \"Argentina\",\n",
      "            \"AUS\": \"Australia\",\n",
      "            \"AUT\": \"Austria\",\n",
      "            \"BEL\": \"Belgium\",\n",
      "            \"BGR\": \"Bulgaria\",\n",
      "            \"BRA\": \"Brazil\",\n",
      "            \"CAN\": \"Canada\",\n",
      "            \"CHE\": \"Switzerland\",\n",
      "            \"CHL\": \"Chile\",\n",
      "            \"CHN\": \"China (People\\u2019s Republic of)\",\n",
      "            \"COL\": \"Colombia\",\n",
      "            \"CRI\": \"Costa Rica\",\n",
      "            \"CZE\": \"Czechia\",\n",
      "            \"DEU\": \"Germany\",\n",
      "            \"DNK\": \"Denmark\",\n",
      "            \"ESP\": \"Spain\",\n",
      "            \"EST\": \"Estonia\",\n",
      "            \"EU25\": \"European Union (25 countries)\",\n",
      "            \"FIN\": \"Finland\",\n",
      "            \"FRA\": \"France\",\n",
      "            \"G20\": \"G20\",\n",
      "            \"GBR\": \"United Kingdom\",\n",
      "            \"GRC\": \"Greece\",\n",
      "            \"HRV\": \"Croatia\",\n",
      "            \"HUN\": \"Hungary\",\n",
      "            \"IDN\": \"Indonesia\",\n",
      "            \"IND\": \"India\",\n",
      "            \"IRL\": \"Ireland\",\n",
      "            \"ISL\": \"Iceland\",\n",
      "            \"ISR\": \"Israel\",\n",
      "            \"ITA\": \"Italy\",\n",
      "            \"JPN\": \"Japan\",\n",
      "            \"KOR\": \"Korea\",\n",
      "            \"LTU\": \"Lithuania\",\n",
      "            \"LUX\": \"Luxembourg\",\n",
      "            \"LVA\": \"Latvia\",\n",
      "            \"MEX\": \"Mexico\",\n",
      "            \"NLD\": \"Netherlands\",\n",
      "            \"NOR\": \"Norway\",\n",
      "            \"NZL\": \"New Zealand\",\n",
      "            \"OECD\": \"OECD\",\n",
      "            \"PER\": \"Peru\",\n",
      "            \"POL\": \"Poland\",\n",
      "            \"PRT\": \"Portugal\",\n",
      "            \"ROU\": \"Romania\",\n",
      "            \"SAU\": \"Saudi Arabia\",\n",
      "            \"SVK\": \"Slovak Republic\",\n",
      "            \"SVN\": \"Slovenia\",\n",
      "            \"SWE\": \"Sweden\",\n",
      "            \"TUR\": \"T\\u00fcrkiye\",\n",
      "            \"USA\": \"United States\",\n",
      "            \"ZAF\": \"South Africa\"\n",
      "        },\n",
      "        \"EDUCATION_LEV\": {\n",
      "            \"ISCED11_1\": \"Primary education\",\n",
      "            \"ISCED11_1T4\": \"Primary to post-secondary non-tertiary education\",\n",
      "            \"ISCED11_1T8\": \"Primary to tertiary education\",\n",
      "            \"ISCED11_2\": \"Lower secondary education\",\n",
      "            \"ISCED11_2_3\": \"Secondary education\",\n",
      "            \"ISCED11_24\": \"Lower secondary general education\",\n",
      "            \"ISCED11_25\": \"Lower secondary vocational education\",\n",
      "            \"ISCED11_3\": \"Upper secondary education\",\n",
      "            \"ISCED11_3_4\": \"Upper secondary and post-secondary non-tertiary all programmes\",\n",
      "            \"ISCED11_34\": \"Upper secondary general education\",\n",
      "            \"ISCED11_34_44\": \"Upper secondary and post-secondary non-tertiary general programmes\",\n",
      "            \"ISCED11_35\": \"Upper secondary vocational education\",\n",
      "            \"ISCED11_35_45\": \"Upper secondary and post-secondary non-tertiary vocational programmes\",\n",
      "            \"ISCED11_4\": \"Post-secondary non-tertiary education\",\n",
      "            \"ISCED11_44\": \"Post-secondary non-tertiary general education\",\n",
      "            \"ISCED11_45\": \"Post-secondary non-tertiary vocational education\",\n",
      "            \"ISCED11_5\": \"Short-cycle tertiary education\",\n",
      "            \"ISCED11_5T8\": \"Tertiary education\",\n",
      "            \"ISCED11_6T8\": \"Bachelor's, Master's and Doctoral or equivalent level\"\n",
      "        },\n",
      "        \"EXP_SOURCE\": {\n",
      "            \"_T\": \"Total\",\n",
      "            \"S13\": \"General government\",\n",
      "            \"S1D_NON_EDU\": \"Private sector (households and other non-educational private entities)\",\n",
      "            \"S1D_NON_EDU_O\": \"Other non-educational private sector\",\n",
      "            \"S2\": \"Rest of the world\"\n",
      "        },\n",
      "        \"EXP_DESTINATION\": {\n",
      "            \"INST_EDU\": \"All educational institutions\",\n",
      "            \"INST_EDU_PRIV\": \"Private educational institutions\",\n",
      "            \"INST_EDU_PRIV_GOV\": \"Government dependent private educational institutions\",\n",
      "            \"INST_EDU_PRIV_IND\": \"Independent private educational institutions\",\n",
      "            \"INST_EDU_PUB\": \"Public educational institutions\"\n",
      "        },\n",
      "        \"EXPENDITURE_TYPE\": {\n",
      "            \"ASERV\": \"Expenditure for ancillary services\",\n",
      "            \"CORE\": \"Expenditure for core services\",\n",
      "            \"DIR_EXP\": \"Expenditure for educational institutions\",\n",
      "            \"NORD\": \"Excluding research and development (R&D)\",\n",
      "            \"RD\": \"Expenditure for R&D in educational institutions\"\n",
      "        },\n",
      "        \"PRICE_BASE\": {\n",
      "            \"_Z\": \"Not applicable\",\n",
      "            \"V\": \"Current prices\"\n",
      "        },\n",
      "        \"UNIT_MEASURE\": {\n",
      "            \"PT_B1GQ_POP\": \"Percentage of GDP per capita\",\n",
      "            \"USD_PPP_ST\": \"US dollars per student, PPP converted\"\n",
      "        },\n",
      "        \"TIME_PERIOD\": {\n",
      "            \"1995\": \"No codelist found\",\n",
      "            \"2021\": \"No codelist found\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "interesting_sessin_variables = ['df_name', 'df_description', 'df_dimension_names', 'df_code_names']\n",
    "\n",
    "# Create a subset dictionary directly from the dataclass instance\n",
    "interesting_content= {var_name: getattr(df_info, var_name) for var_name in interesting_sessin_variables}\n",
    "\n",
    "# Serialize the subset dictionary to a JSON string\n",
    "import json\n",
    "json_str = json.dumps(interesting_content, indent=4)\n",
    "\n",
    "# Print the JSON string\n",
    "print(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_name', 'df_description', 'df_dimension_names', 'df_code_names'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interesting_content.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persona = \"\"\"You are a data analyst working for a government agency. You have been tasked with analyzing the expenditure on educational institutions per full-time equivalent student. You need to understand the dataset's structure, including the dimension names and code names, to effectively filter and analyze the data. Your goal is to provide insights and recommendations based on the dataset to inform policy decisions and resource allocation in the education sector.\"\"\"\n",
    "    \n",
    "def select_info(user_question):\n",
    "    persona = \"\"\"\n",
    "    You are a coordinator helping data analysts at a government agency. \n",
    "    You have been asked to help them find the best data source to answer a specific user question.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please select the best information from the sources listed below to answer the user's question. \n",
    "    You are only allowed to choose one source. \n",
    "    Please respect the formatting! For example: your answer should look like \"df_code_names\".\n",
    "    If you are not able to find the answer in the sources listed below, please select \"None\".\n",
    "\n",
    "    ### Sources:\n",
    "    1. [df_name]: Name of the dataset. Usually 5-10 words.\n",
    "    2. [df_description]: Detailed description of the dataset, including what it contains and how it can be filtered.\n",
    "    3. [df_dimension_names]: The list of all dimension codes of the DataFlow as keys and their corresponding names in English as values.\n",
    "    - Example:\n",
    "        - 'EDUCATION_LEV': 'Education level'\n",
    "        - 'EXP_SOURCE': 'Financing source'\n",
    "    4. [df_code_names]: The list of all codes used in the DataFlow as keys and their corresponding names in English as values.\n",
    "        - Example:\n",
    "            - 'EXP_SOURCE':\n",
    "                - 'S13': 'General government'\n",
    "                - 'S1D_NON_EDU': 'Private sector'\n",
    "\n",
    "    ### User Question:\n",
    "    {user_question}\n",
    "    \"\"\"\n",
    "    return LLM.model(prompt, persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected source: df_name, Cost: 4.65e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Expenditure on educational institutions per full-time equivalent student'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"What is the name of the dataset?\"\n",
    "key, cost = select_info(user_question)\n",
    "print(f\"Selected source: {key}, Cost: {cost}\")\n",
    "interesting_content[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(user_question, interesting_content):\n",
    "    key, cost = select_info(user_question)\n",
    "    print(f\"Selected source: {key}, Cost: {cost}\")\n",
    "\n",
    "    persona = \"\"\"You are a helpful data analyst working for OECD.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please provide the answer to the following user question: \n",
    "    {user_question}\n",
    "    Please use the information from the source that was selected as the best source to answer the question:\n",
    "    {interesting_content[key]}\n",
    "    \"\"\"\n",
    "\n",
    "    return LLM.model(prompt, persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the idea works but not in any scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected source: df_name, Cost: 4.65e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The name of the dataset is \"Expenditure on educational institutions per full-time equivalent student.\"',\n",
       " 2.22e-05)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"What is the name of the dataset?\"\n",
    "answer_question(user_question, interesting_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected source: None, Cost: 4.74e-05\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'None'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the definition of the education level \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISCED11_34_44\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43manswer_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_question\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteresting_content\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m, in \u001b[0;36manswer_question\u001b[0;34m(user_question, interesting_content)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Cost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m persona \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a helpful data analyst working for OECD.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mPlease provide the answer to the following user question: \u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_question\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mPlease use the information from the source that was selected as the best source to answer the question:\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43minteresting_content\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLM\u001b[38;5;241m.\u001b[39mmodel(prompt, persona)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None'"
     ]
    }
   ],
   "source": [
    "user_question = \"What is the definition of the education level 'ISCED11_34_44'?\"\n",
    "answer_question(user_question, interesting_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Approaches for Working with Data and Large Language Models (LLMs)\n",
    "\n",
    "When using LLMs to work with data, there are two main approaches we can take:\n",
    "\n",
    "1. **Send All the Data to the LLM**:\n",
    "   - We extract everything important from the data (in this case, from SDMX, which is a standard for sharing statistical data).\n",
    "   - Then, we convert this information into a compact form (expressed in tokens, which are chunks of text that the LLM understands).\n",
    "   - Finally, we send all the relevant information to the LLM at once and ask it to generate an answer.\n",
    "\n",
    "2. **Use a Search-First Approach (RAG)**:\n",
    "   - Instead of sending everything to the LLM, we can use a system called RAG (Retrieval-Augmented Generation).\n",
    "   - First, we search our stored information (like a database) to find the most relevant entries for the task.\n",
    "   - We then send only the top few results to the LLM and ask it to generate an answer based on those results.\n",
    "   \n",
    "The second approach helps limit the amount of information the LLM needs to process, making it more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed the metadata for better search\n",
    "- going through items individually to prepare adequate phrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten_name_and_description(info):\n",
    "\n",
    "    return [\n",
    "          (\"The DataFrame's name\", info.df_name)\n",
    "        , (info.df_name, \"The DataFrame's name\")\n",
    "        , (\"The DataFrame's description\", info.df_description)\n",
    "        , (info.df_description, \"The DataFrame's description\")\n",
    "    ]\n",
    "\n",
    "def flatten_dimensions(info):\n",
    "    ans = []\n",
    "    for code, name in info.df_dimension_names.items():\n",
    "        meta_statement = f\"The name that corresponds to the dimension code: '{code}' is {name}.\"\n",
    "        ans.append((code, meta_statement))\n",
    "        ans.append((name, meta_statement))\n",
    "        ans.append((f\"What name that corresponds to the dimension code: '{code}'?\", meta_statement))\n",
    "        ans.append((f\"What is the dimension code for '{name}'?\", meta_statement))\n",
    "    return ans\n",
    "\n",
    "def flatten_codes(info):\n",
    "    ans = []\n",
    "    for code_list_id in info.df_code_names:\n",
    "        for code, name in info.df_code_names[code_list_id].items():\n",
    "            meta_statement = f\"The English name of the code '{code}' within the code list ID '{code_list_id}' is '{name}'.\"\n",
    "            ans.append((code, meta_statement))\n",
    "            ans.append((name, meta_statement))\n",
    "            ans.append((f\"What is the English name of the code '{code}' within the code list ID '{code_list_id}'?\", meta_statement))\n",
    "            ans.append((f\"What is the code for '{name}' within the code list ID '{code_list_id}'?\", meta_statement))\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info_for_embedding = list(tuple())\n",
    "flat_info_for_embedding.extend(flatten_name_and_description(df_info))\n",
    "flat_info_for_embedding.extend(flatten_dimensions(df_info))\n",
    "flat_info_for_embedding.extend(flatten_codes(df_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the flattened information to a JSON file\n",
    "import json\n",
    "with open('flat_info_for_embedding.json', 'w') as f:\n",
    "    json.dump(flat_info_for_embedding, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['full_name_of_the_dataflow', 'description_of_the_dataflow', 'dimension_codes_and_their_english_names', 'code_list_codes_and_their_english_names'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping of old keys to new keys\n",
    "key_mapping = {\n",
    "    'df_name': 'full_name_of_the_dataflow',\n",
    "    'df_description': 'description_of_the_dataflow',\n",
    "    'df_dimension_names': 'dimension_codes_and_their_english_names',\n",
    "    'df_code_names': 'code_list_codes_and_their_english_names'\n",
    "}\n",
    "\n",
    "# Create a new dictionary with updated key names\n",
    "new_interesting_content = {key_mapping.get(k, k): v for k, v in interesting_content.items()}\n",
    "\n",
    "# Print the new dictionary\n",
    "new_interesting_content.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function does the following:\n",
    "\n",
    "1. It uses a recursive approach to traverse the dictionary.\n",
    "2. For each leaf node (where the value is not a dictionary or list), it creates two entries in the result list:\n",
    "    - One with the key as the main key and (position, value) as the value.\n",
    "    - Another with the value as the main key and (position, key) as the value.\n",
    "3. For 'df_name' and 'df_description', it prefixes 'Code' to the key and 'Name' to the value in the resulting structures.\n",
    "4. The position is represented as a dot-separated string of the keys leading to the leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dictionary(d):\n",
    "    result = []\n",
    "    \n",
    "    def flatten(data, path=None):\n",
    "        if path is None:\n",
    "            path = []\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                new_path = path + [str(key)]\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    flatten(value, new_path)\n",
    "                else:\n",
    "                    position = '.'.join(map(str, new_path))\n",
    "                    if path and path[0] in ['df_name', 'df_description']:\n",
    "                        result.append({f\"Code: {key}\": (position, value)})\n",
    "                        result.append({f\"Name: {value}\": (position, key)})\n",
    "                    else:\n",
    "                        result.append({key: (position, value)})\n",
    "                        result.append({value: (position, key)})\n",
    "        elif isinstance(data, list):\n",
    "            for i, item in enumerate(data):\n",
    "                flatten(item, path + [str(i)])\n",
    "    \n",
    "    flatten(d)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = flatten_dictionary(new_interesting_content)\n",
    "for item in flattened:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the flattened dictionary to a JSON file\n",
    "import json\n",
    "with open('flattened_interesting_content.json', 'w') as f:\n",
    "    json.dump(flattened, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
