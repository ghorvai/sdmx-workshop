{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an LLM to Answer Questions Based on Provided Sources\n",
    "\n",
    "By providing the source that grounds the model, we can control the information it returns, ensuring it answers questions based on the provided sources instead of its own knowledge:\n",
    "\n",
    "1. **Ingesting the Document**: Preprocess the text from the provided sources and divide it into manageable chunks if necessary. This will ensure the entire document can be used without exceeding token limits. (The maximum number of tokens an LLM can process in a single input called the **context length** or **maximum context length**)\n",
    "\n",
    "2. **Embedding the Context**: For each question, construct a prompt that embeds the relevant sections of the source document directly within the prompt.\n",
    "\n",
    "3. **Crafting the Prompt**:\n",
    "   - Start with an instruction that clearly states the priority of the source: \"Based on the provided document, answer the following question:\"\n",
    "   - Insert the relevant chunk of the source text.\n",
    "   - Follow up with the specific question.\n",
    "\n",
    "4. **Controlling the Modelâ€™s Output**:\n",
    "   - Use parameters like temperature = 0 to ensure factual outputs.\n",
    "   - Optionally, add explicit instructions to the prompt to disregard any conflicting information from its pre-trained knowledge base.\n",
    "\n",
    "5. **Example Prompt Construction**:\n",
    "   ```markdown\n",
    "   Based on the provided document, answer the following question:\n",
    "   \n",
    "   Document Excerpt: \"The ISCED11_34_44 code refers to 'Upper secondary and post-secondary non-tertiary general programmes'. This classification is part of the International Standard Classification of Education framework.\"\n",
    "\n",
    "   Question: What does the code ISCED11_34_44 mean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When importing files from a different directory, you need to add the directory to the path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the chat_bot directory\n",
    "chat_bot_path = os.path.join(current_dir, '..', 'chat_bot')\n",
    "\n",
    "# Add the chat_bot directory to the Python path\n",
    "sys.path.append(chat_bot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the LLM and SDMX_DataFlow classes from the chat_bot folder that is one level above the current directory. To do this, we need to add the parent directory to the path.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "\tsys.path.append(module_path)\n",
    "\n",
    "from chat_bot import LLM\n",
    "from chat_bot import SDMX_DataFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing SDMX information for a chosen DataFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://sdmx.oecd.org/public/rest/dataflow/OECD.EDU.IMEP/DSD_EAG_UOE_FIN@DF_UOE_INDIC_FIN_PERSTUD/1.0?references=all'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_perstud = {\"agency\": \"OECD.EDU.IMEP\",\n",
    "\"id\": \"DSD_EAG_UOE_FIN@DF_UOE_INDIC_FIN_PERSTUD\",\n",
    "\"version\": \"1.0\",\n",
    "\"name\": \"Expenditure on educational institutions per full-time equivalent student\",\n",
    "\"description\": \"This dataset contains data on expenditure per full-time equivalent student and per full-time equivalent student as a percentage of GPD per capita. The default table displays data for 2020 in current USD PPP and as a percentage of GDP per capita, from all expenditure sources, and unfiltered by type of expenditure. The selection can be changed to display data: by year, by source of expenditure, by destination of expenditure and by type of expenditure. Please note that some categories are mutually exclusive. </p><p>For more information, please consult <a href=\\\"https://www.oecd-ilibrary.org/sites/e13bef63-en/1/3/4/index.html?itemId=%20/content/publication/e13bef63-en&_csp_=a4f4b3d408c9dd70d167f10de61b8717&itemIGO=oecd&itemContentType=book\\\"><i>Education at a Glance 2023</i></a>. Additional details regarding the methodology used, references to the sources, and specific notes for each country can be found in <a href=\\\"https://www.oecd-ilibrary.org/sites/301fa18e-en/index.html?itemId=/content/component/301fa18e-en\\\"><i>Education at a Glance 2023 Sources, Methodologies and Technical Notes</i></a>.\"\n",
    "}\n",
    "\n",
    "dataflow_details_url = f'https://sdmx.oecd.org/public/rest/dataflow/{fin_perstud[\"agency\"]}/{fin_perstud[\"id\"]}/{fin_perstud[\"version\"]}?references=all'\n",
    "dataflow_details_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = SDMX_DataFlow.Dataflow(dataflow_details_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.populate_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://openai.com/api/pricing/\n",
    "MODEL_PRICING_PER_M_TOKENS = {\n",
    "    'gpt-4o': {'prompt_tokens': 5.00, 'completion_tokens': 15.00},\n",
    "    'gpt-4o-2024-08-06': {'prompt_tokens': 2.50, 'completion_tokens': 10.00},\n",
    "    'gpt-4o-mini': {'prompt_tokens': 0.150, 'completion_tokens': 0.600},\n",
    "    'gpt-4o-mini-2024-07-18': {'prompt_tokens': 0.150, 'completion_tokens': 0.600},\n",
    "    'o1-preview': {'prompt_tokens': 15.00, 'completion_tokens': 60.00}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `tiktoken` library for estimating the cost of LLM calls is a great idea for several reasons:\n",
    "\n",
    "1. **Token Efficiency**: LLMs, such as those from OpenAI, charge based on the number of tokens processed. The `tiktoken` library allows you to precisely calculate the number of tokens your input will generate, providing an accurate estimate of the cost.\n",
    "2. **Cost Management**: By knowing the token count in advance, you can manage and optimize your prompts to stay within your budget. This helps avoid unexpected costs and ensures efficient use of the LLM.\n",
    "3. **Performance Optimization**: Estimating token usage helps in optimizing the performance of your model calls. You can adjust your inputs to ensure they are within the token limits, preventing truncation or errors during processing.\n",
    "4. **Transparency**: It provides transparency in understanding how your inputs are tokenized, giving you insights into the tokenization process and enabling better control over the generated text.\n",
    "\n",
    "Overall, the `tiktoken` library is a valuable tool for effectively managing and predicting the costs associated with using LLMs, ensuring you can make informed decisions about your AI usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url                            contains #44 tokens\n",
      "df_details_json                contains #223153 tokens\n",
      "df_name                        contains #11 tokens\n",
      "df_description                 contains #274 tokens\n",
      "df_dimension_names             contains #147 tokens\n",
      "df_code_names                  contains #1005 tokens\n"
     ]
    }
   ],
   "source": [
    "# print the memory size of instance variables\n",
    "import tiktoken\n",
    "\n",
    "# Load the encoding for the GPT model you're using\n",
    "# For GPT-4 or GPT-3.5, you can use the `cl100k_base` encoding\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "for var in vars(df_info):\n",
    "    content = getattr(df_info, var)\n",
    "    text = str(content)\n",
    "    # Tokenize the string\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"{var:30} contains #{len(tokens)} tokens\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming each answer is always 100 tokens, independent of input size, we can calculate the cost for 1000 calls as follows:\n",
    "\n",
    "**Model Pricing:**\n",
    "- **gpt-4o**: $5.00 / 1M input tokens, $15.00 / 1M output tokens\n",
    "- **gpt-4o-mini**: $0.150 / 1M input tokens, $0.600 / 1M output tokens\n",
    "- **o1-preview**: $15.00 / 1M input tokens, $60.00 / 1M output tokens\n",
    "\n",
    "```python\n",
    "1000 * len(tokens) * MODEL_PRICING_PER_M_TOKENS[model_name]['prompt_tokens'] / 1000000  # Cost of prompt\n",
    "1000 * 100 * MODEL_PRICING_PER_M_TOKENS[model_name]['completion_tokens'] / 1000000      # Cost of completion\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini:\n",
      "Total cost for 1000 calls on the raw SDMX metadata: $33.53295\n",
      "Total cost for 1000 calls on the parsed code names: $0.21075\n",
      "==========================\n",
      "Model: gpt-4o:\n",
      "Total cost for 1000 calls on the raw SDMX metadata: $1117.265\n",
      "Total cost for 1000 calls on the parsed code names: $6.525\n",
      "==========================\n",
      "Model: o1-preview:\n",
      "Total cost for 1000 calls on the raw SDMX metadata: $3353.295\n",
      "Total cost for 1000 calls on the parsed code names: $21.075\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# json to text to tokens:\n",
    "raw_json_text = str(df_info.df_details_json)\n",
    "raw_json_tokens = encoding.encode(raw_json_text)\n",
    "parsed_metadata_text = str(df_info.df_code_names)\n",
    "parsed_metadata_tokens = encoding.encode(parsed_metadata_text)\n",
    "completion_tokens = 100\n",
    "\n",
    "for model_name in (\"gpt-4o-mini\", \"gpt-4o\", \"o1-preview\"):\n",
    "    print(f\"Model: {model_name}:\")\n",
    "    raw_prompt_cost = 1000 * len(raw_json_tokens) * MODEL_PRICING_PER_M_TOKENS[model_name]['prompt_tokens'] / 1000000\n",
    "    parsed_prompt_cost = 1000 * len(parsed_metadata_tokens) * MODEL_PRICING_PER_M_TOKENS[model_name]['prompt_tokens'] / 1000000\n",
    "    completion_cost = 1000 * completion_tokens * MODEL_PRICING_PER_M_TOKENS[model_name]['completion_tokens'] / 1000000\n",
    "    print(f\"Total cost for 1000 calls on the raw SDMX metadata: ${raw_prompt_cost + completion_cost}\")\n",
    "    print(f\"Total cost for 1000 calls on the parsed code names: ${parsed_prompt_cost + completion_cost}\")\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>We can spend about 150 times more for the same answer by passing everything to the LLM instead of just selecting relevant data.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Challenge of Too Much Data: Finding Whatâ€™s Relevant for the LLM\n",
    "\n",
    "When working with large datasets like SDMX, there is often **a lot more data than we actually need** to answer specific questions. For example:\n",
    "\n",
    "- A URL might only take up 44 tokens.\n",
    "- The name of a dataframe takes up just 11 tokens.\n",
    "- But the full details of the data (in JSON format) can use **223,153 tokens**!\n",
    "\n",
    "#### The Problem:\n",
    "If the user only asks for something simple, like the name of the dataframe, we donâ€™t need to send all 223,153 tokens. We could give the answer with just 11 tokens. However, if we send all the data to the LLM, it creates two big challenges:\n",
    "1. **Efficiency**: Itâ€™s like trying to find a needle in a haystack. The LLM would have to search through tons of unnecessary data to find what matters.\n",
    "2. **Cost**: Sending large amounts of data to the LLM is expensive. The more tokens we use, the higher the cost.\n",
    "\n",
    "#### The Solution:\n",
    "A good idea is to **prepare the data before sending it to the LLM**, which is part of whatâ€™s called an \"agentic approach.\" This means we make sure the LLM only gets the important and relevant information it needs to answer the question, rather than flooding it with everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"df_name\": \"Expenditure on educational institutions per full-time equivalent student\",\n",
      "    \"df_description\": \"This dataset contains data on expenditure per full-time equivalent student and per full-time equivalent student as a percentage of GPD per capita. The default table displays data for 2020 in current USD PPP and as a percentage of GDP per capita, from all expenditure sources, and unfiltered by type of expenditure. The selection can be changed to display data: by year, by source of expenditure, by destination of expenditure and by type of expenditure. Please note that some categories are mutually exclusive. </p><p>For more information, please consult <a href=\\\"https://www.oecd-ilibrary.org/sites/e13bef63-en/1/3/4/index.html?itemId=%20/content/publication/e13bef63-en&_csp_=a4f4b3d408c9dd70d167f10de61b8717&itemIGO=oecd&itemContentType=book\\\"><i>Education at a Glance 2023</i></a>. Additional details regarding the methodology used, references to the sources, and specific notes for each country can be found in <a href=\\\"https://www.oecd-ilibrary.org/sites/301fa18e-en/index.html?itemId=/content/component/301fa18e-en\\\"><i>Education at a Glance 2023 Sources, Methodologies and Technical Notes</i></a>.\",\n",
      "    \"df_dimension_names\": {\n",
      "        \"MEASURE\": \"Measure\",\n",
      "        \"REF_AREA\": \"Reference area\",\n",
      "        \"EDUCATION_LEV\": \"Education level\",\n",
      "        \"INTENSITY\": \"Intensity\",\n",
      "        \"EXP_SOURCE\": \"Financing source\",\n",
      "        \"EXP_DESTINATION\": \"Destination of expenditure\",\n",
      "        \"EXPENDITURE_TYPE\": \"Type of expenditure\",\n",
      "        \"INST_TYPE_EDU\": \"Type of educational institution\",\n",
      "        \"PRICE_BASE\": \"Price base\",\n",
      "        \"BASE_PER\": \"Base period\",\n",
      "        \"TIME_PERIOD\": \"Time period\",\n",
      "        \"OBS_VALUE\": \"Observation value\",\n",
      "        \"OBS_STATUS\": \"Observation status\",\n",
      "        \"UNIT_MULT\": \"Unit multiplier\",\n",
      "        \"UNIT_MEASURE\": \"Unit of measure\",\n",
      "        \"DECIMALS\": \"Decimals\"\n",
      "    },\n",
      "    \"df_code_names\": {\n",
      "        \"MEASURE\": {\n",
      "            \"FIN_PERSTUD\": \"Expenditure per full-time equivalent student\"\n",
      "        },\n",
      "        \"REF_AREA\": {\n",
      "            \"ARG\": \"Argentina\",\n",
      "            \"AUS\": \"Australia\",\n",
      "            \"AUT\": \"Austria\",\n",
      "            \"BEL\": \"Belgium\",\n",
      "            \"BGR\": \"Bulgaria\",\n",
      "            \"BRA\": \"Brazil\",\n",
      "            \"CAN\": \"Canada\",\n",
      "            \"CHE\": \"Switzerland\",\n",
      "            \"CHL\": \"Chile\",\n",
      "            \"CHN\": \"China (People\\u2019s Republic of)\",\n",
      "            \"COL\": \"Colombia\",\n",
      "            \"CRI\": \"Costa Rica\",\n",
      "            \"CZE\": \"Czechia\",\n",
      "            \"DEU\": \"Germany\",\n",
      "            \"DNK\": \"Denmark\",\n",
      "            \"ESP\": \"Spain\",\n",
      "            \"EST\": \"Estonia\",\n",
      "            \"EU25\": \"European Union (25 countries)\",\n",
      "            \"FIN\": \"Finland\",\n",
      "            \"FRA\": \"France\",\n",
      "            \"G20\": \"G20\",\n",
      "            \"GBR\": \"United Kingdom\",\n",
      "            \"GRC\": \"Greece\",\n",
      "            \"HRV\": \"Croatia\",\n",
      "            \"HUN\": \"Hungary\",\n",
      "            \"IDN\": \"Indonesia\",\n",
      "            \"IND\": \"India\",\n",
      "            \"IRL\": \"Ireland\",\n",
      "            \"ISL\": \"Iceland\",\n",
      "            \"ISR\": \"Israel\",\n",
      "            \"ITA\": \"Italy\",\n",
      "            \"JPN\": \"Japan\",\n",
      "            \"KOR\": \"Korea\",\n",
      "            \"LTU\": \"Lithuania\",\n",
      "            \"LUX\": \"Luxembourg\",\n",
      "            \"LVA\": \"Latvia\",\n",
      "            \"MEX\": \"Mexico\",\n",
      "            \"NLD\": \"Netherlands\",\n",
      "            \"NOR\": \"Norway\",\n",
      "            \"NZL\": \"New Zealand\",\n",
      "            \"OECD\": \"OECD\",\n",
      "            \"PER\": \"Peru\",\n",
      "            \"POL\": \"Poland\",\n",
      "            \"PRT\": \"Portugal\",\n",
      "            \"ROU\": \"Romania\",\n",
      "            \"SAU\": \"Saudi Arabia\",\n",
      "            \"SVK\": \"Slovak Republic\",\n",
      "            \"SVN\": \"Slovenia\",\n",
      "            \"SWE\": \"Sweden\",\n",
      "            \"TUR\": \"T\\u00fcrkiye\",\n",
      "            \"USA\": \"United States\",\n",
      "            \"ZAF\": \"South Africa\"\n",
      "        },\n",
      "        \"EDUCATION_LEV\": {\n",
      "            \"ISCED11_1\": \"Primary education\",\n",
      "            \"ISCED11_1T4\": \"Primary to post-secondary non-tertiary education\",\n",
      "            \"ISCED11_1T8\": \"Primary to tertiary education\",\n",
      "            \"ISCED11_2\": \"Lower secondary education\",\n",
      "            \"ISCED11_2_3\": \"Secondary education\",\n",
      "            \"ISCED11_24\": \"Lower secondary general education\",\n",
      "            \"ISCED11_25\": \"Lower secondary vocational education\",\n",
      "            \"ISCED11_3\": \"Upper secondary education\",\n",
      "            \"ISCED11_3_4\": \"Upper secondary and post-secondary non-tertiary all programmes\",\n",
      "            \"ISCED11_34\": \"Upper secondary general education\",\n",
      "            \"ISCED11_34_44\": \"Upper secondary and post-secondary non-tertiary general programmes\",\n",
      "            \"ISCED11_35\": \"Upper secondary vocational education\",\n",
      "            \"ISCED11_35_45\": \"Upper secondary and post-secondary non-tertiary vocational programmes\",\n",
      "            \"ISCED11_4\": \"Post-secondary non-tertiary education\",\n",
      "            \"ISCED11_44\": \"Post-secondary non-tertiary general education\",\n",
      "            \"ISCED11_45\": \"Post-secondary non-tertiary vocational education\",\n",
      "            \"ISCED11_5\": \"Short-cycle tertiary education\",\n",
      "            \"ISCED11_5T8\": \"Tertiary education\",\n",
      "            \"ISCED11_6T8\": \"Bachelor's, Master's and Doctoral or equivalent level\"\n",
      "        },\n",
      "        \"EXP_SOURCE\": {\n",
      "            \"_T\": \"Total\",\n",
      "            \"S13\": \"General government\",\n",
      "            \"S1D_NON_EDU\": \"Private sector (households and other non-educational private entities)\",\n",
      "            \"S1D_NON_EDU_O\": \"Other non-educational private sector\",\n",
      "            \"S2\": \"Rest of the world\"\n",
      "        },\n",
      "        \"EXP_DESTINATION\": {\n",
      "            \"INST_EDU\": \"All educational institutions\",\n",
      "            \"INST_EDU_PRIV\": \"Private educational institutions\",\n",
      "            \"INST_EDU_PRIV_GOV\": \"Government dependent private educational institutions\",\n",
      "            \"INST_EDU_PRIV_IND\": \"Independent private educational institutions\",\n",
      "            \"INST_EDU_PUB\": \"Public educational institutions\"\n",
      "        },\n",
      "        \"EXPENDITURE_TYPE\": {\n",
      "            \"ASERV\": \"Expenditure for ancillary services\",\n",
      "            \"CORE\": \"Expenditure for core services\",\n",
      "            \"DIR_EXP\": \"Expenditure for educational institutions\",\n",
      "            \"NORD\": \"Excluding research and development (R&D)\",\n",
      "            \"RD\": \"Expenditure for R&D in educational institutions\"\n",
      "        },\n",
      "        \"PRICE_BASE\": {\n",
      "            \"_Z\": \"Not applicable\",\n",
      "            \"V\": \"Current prices\"\n",
      "        },\n",
      "        \"UNIT_MEASURE\": {\n",
      "            \"PT_B1GQ_POP\": \"Percentage of GDP per capita\",\n",
      "            \"USD_PPP_ST\": \"US dollars per student, PPP converted\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "interesting_sessin_variables = ['df_name', 'df_description', 'df_dimension_names', 'df_code_names']\n",
    "\n",
    "# Create a subset dictionary directly from the dataclass instance\n",
    "interesting_content= {var_name: getattr(df_info, var_name) for var_name in interesting_sessin_variables}\n",
    "\n",
    "# Serialize the subset dictionary to a JSON string\n",
    "import json\n",
    "json_str = json.dumps(interesting_content, indent=4)\n",
    "\n",
    "# Print the JSON string\n",
    "print(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_name', 'df_description', 'df_dimension_names', 'df_code_names'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interesting_content.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persona = \"\"\"You are a data analyst working for a government agency. You have been tasked with analyzing the expenditure on educational institutions per full-time equivalent student. You need to understand the dataset's structure, including the dimension names and code names, to effectively filter and analyze the data. Your goal is to provide insights and recommendations based on the dataset to inform policy decisions and resource allocation in the education sector.\"\"\"\n",
    "    \n",
    "def select_info(user_question):\n",
    "    persona = \"\"\"\n",
    "    You are a coordinator helping data analysts at a government agency. \n",
    "    You have been asked to help them find the best data source to answer a specific user question.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please select the best information from the sources listed below to answer the user's question. \n",
    "    You are only allowed to choose one source. \n",
    "    Please respect the formatting! For example: your answer should look like \"df_code_names\".\n",
    "    If you are not able to find the answer in the sources listed below, please select \"None\".\n",
    "\n",
    "    ### Sources:\n",
    "    1. [df_name]: Name of the dataset. Usually 5-10 words.\n",
    "    2. [df_description]: Detailed description of the dataset, including what it contains and how it can be filtered.\n",
    "    3. [df_dimension_names]: The list of all dimension codes of the DataFlow as keys and their corresponding names in English as values.\n",
    "    - Example:\n",
    "        - 'EDUCATION_LEV': 'Education level'\n",
    "        - 'EXP_SOURCE': 'Financing source'\n",
    "    4. [df_code_names]: The list of all codes used in the DataFlow as keys and their corresponding names in English as values.\n",
    "        - Example:\n",
    "            - 'EXP_SOURCE':\n",
    "                - 'S13': 'General government'\n",
    "                - 'S1D_NON_EDU': 'Private sector'\n",
    "\n",
    "    ### User Question:\n",
    "    {user_question}\n",
    "    \"\"\"\n",
    "    return LLM.model(prompt, persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected source: df_name, Cost: 4.65e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Expenditure on educational institutions per full-time equivalent student'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"What is the name of the dataset?\"\n",
    "key, cost = select_info(user_question)\n",
    "print(f\"Selected source: {key}, Cost: {cost}\")\n",
    "interesting_content[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(user_question, interesting_content):\n",
    "    key, cost = select_info(user_question)\n",
    "    print(f\"Selected source: {key}, Cost: {cost}\")\n",
    "\n",
    "    persona = \"\"\"You are a helpful data analyst working for OECD.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please provide the answer to the following user question: \n",
    "    {user_question}\n",
    "    Please use the information from the source that was selected as the best source to answer the question:\n",
    "    {interesting_content[key]}\n",
    "    \"\"\"\n",
    "\n",
    "    return LLM.model(prompt, persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the idea works but not in any scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected source: df_name, Cost: 4.65e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The name of the dataset is \"Expenditure on educational institutions per full-time equivalent student.\"',\n",
       " 2.22e-05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"What is the name of the dataset?\"\n",
    "answer_question(user_question, interesting_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected source: None, Cost: 4.74e-05\n",
      "The call failed with the following error: 'None'\n"
     ]
    }
   ],
   "source": [
    "# this call should fail because the LLM cannot decide where to look for the information\n",
    "user_question = \"What is the definition of the education level 'ISCED11_34_44'?\"\n",
    "try:\n",
    "    answer_question(user_question, interesting_content)\n",
    "except Exception as e:\n",
    "    print(f\"The call failed with the following error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Approaches for Working with Data and Large Language Models (LLMs)\n",
    "\n",
    "When using LLMs to work with data, there are two main approaches we can take:\n",
    "\n",
    "1. **Send All the Data to the LLM**:\n",
    "   - We extract everything important from the data (in this case, from SDMX, which is a standard for sharing statistical data).\n",
    "   - Then, we convert this information into a compact form (expressed in tokens, which are chunks of text that the LLM understands).\n",
    "   - Finally, we send all the relevant information to the LLM at once and ask it to generate an answer.\n",
    "\n",
    "2. **Use a Search-First Approach (RAG)**:\n",
    "   - Instead of sending everything to the LLM, we can use a system called RAG (Retrieval-Augmented Generation).\n",
    "   - First, we search our stored information (like a database) to find the most relevant entries for the task.\n",
    "   - We then send only the top few results to the LLM and ask it to generate an answer based on those results.\n",
    "   \n",
    "The second approach helps limit the amount of information the LLM needs to process, making it more efficient.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
